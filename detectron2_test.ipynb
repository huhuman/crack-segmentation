{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some common libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime, os\n",
    "import time\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog, transforms, build_detection_test_loader, build_detection_train_loader\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.utils.visualizer import ColorMode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cracks_dicts(img_dir):\n",
    "    dataset_dicts = []\n",
    "    image_paths = list(sorted(os.listdir(img_dir + 'image/')))\n",
    "    mask_paths = None\n",
    "    if os.path.exists(img_dir+'mask/'):\n",
    "        mask_paths = list(sorted(os.listdir(img_dir+'mask/')))\n",
    "    for idx, v in enumerate(image_paths):\n",
    "        record = {}\n",
    "        \n",
    "        filename = os.path.join(img_dir, 'image/', v)\n",
    "        height, width = cv2.imread(filename).shape[:2]\n",
    "        \n",
    "        record[\"file_name\"] = filename\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "\n",
    "        if mask_paths:\n",
    "            mask_path = img_dir + \"mask/\" + mask_paths[idx]\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)  # HxWxC\n",
    "            contours,_=cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) \n",
    "\n",
    "            objs = []\n",
    "            for cnt in contours : \n",
    "                approx = cv2.approxPolyDP(cnt, 0.009 * cv2.arcLength(cnt, True), True) \n",
    "                if approx.shape[0] < 3:\n",
    "                    continue\n",
    "                # cv2.drawContours(image, [approx], 0, (0, 0, 255), 1) \n",
    "                # get bounding box coordinates for each mask\n",
    "                px = [pos[0][0] for pos in approx]\n",
    "                py = [pos[0][1] for pos in approx]\n",
    "                poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\n",
    "                poly = [p for x in poly for p in x]\n",
    "                obj = {\n",
    "                    \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
    "                    \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                    \"segmentation\": [poly],\n",
    "                    \"category_id\": 0,\n",
    "                    \"iscrowd\": 0\n",
    "                }\n",
    "                objs.append(obj)\n",
    "            record[\"annotations\"] = objs\n",
    "            record[\"sem_seg_file_name\"] = mask_path # for segmentation evaluator\n",
    "            record[\"seg_file_name\"] = mask_path\n",
    "        else:\n",
    "            record[\"annotations\"] = [{\n",
    "                    \"bbox\": [0, 0, 0, 0],\n",
    "                    \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                    \"segmentation\": [(0, 0), (0, 0), (0, 0)],\n",
    "                    \"category_id\": 0,\n",
    "                    \"iscrowd\": 0\n",
    "                }]\n",
    "            record[\"sem_seg_file_name\"] = '' # for segmentation evaluator\n",
    "        dataset_dicts.append(record)\n",
    "    return dataset_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting for dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '/home/aicenter/Documents/hsu/data/EWSHM/exp3_validation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(name='cracks_test',\n",
       "          thing_classes=['crack'],\n",
       "          thing_colors=[(96, 151, 255)])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DatasetCatalog.clear()\n",
    "DatasetCatalog.register(\"cracks_test\", lambda d= \"test\": get_cracks_dicts(test_dir))\n",
    "MetadataCatalog.get(\"cracks_test\").set(thing_classes=[\"crack\"], thing_colors=[(96, 151, 255)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512 \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (crack)\n",
    "cfg.MODEL.WEIGHTS = \"./models/EWSHM/exp3/model_final.pth\"\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model\n",
    "cfg.DATASETS.TEST = (\"cracks_test\", )\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45516800"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, predictor.model.backbone.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iterator for test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = build_detection_test_loader(cfg, \"cracks_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mIoU Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# borrows from pytorch-deeplab-xception\n",
    "from utils.metrics import Evaluator\n",
    "evaluator = Evaluator(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aicenter/Documents/hsu/data/EWSHM/exp3_validation/image/00021.png\n",
      "/home/aicenter/Documents/hsu/data/EWSHM/exp3_validation/image/crop_93.png\n",
      "Validation:\n",
      "mIoU:[0.97280165 0.29616697]\n",
      "Acc:0.9731094110479055, Acc_class:0.779738265870734, mIoU:0.6344843090506382, fwIoU: 0.9595667021788953\n"
     ]
    }
   ],
   "source": [
    "is_trans = 'Trans' in test_dir\n",
    "root, folder_name = '', ''\n",
    "if is_trans:\n",
    "    split_path = file_name.split('/')\n",
    "    folder_name = '_'.join(split_path[-3].split('_')[:-1])\n",
    "    root = '/'.join(split_path[:-3])\n",
    "    \n",
    "evaluator.reset()\n",
    "for idx, d in enumerate(test_loader):\n",
    "    file_name = d[0][\"file_name\"]\n",
    "    im = cv2.imread(file_name)\n",
    "    if idx%50==0:\n",
    "        print(file_name)\n",
    "    outputs = predictor(im)\n",
    "    \n",
    "    image_name = file_name.split('/')[-1]\n",
    "    if is_trans:\n",
    "        original_path = '%s/%s/image/%s'%(root, folder_name, image_name)\n",
    "        im = cv2.imread(original_path)\n",
    "    masks = outputs['instances'].pred_masks.cpu().numpy()\n",
    "    masks = masks[outputs['instances'].scores.cpu().numpy() > cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST]\n",
    "    mask = np.sum(masks, axis=0) > 0\n",
    "    target = cv2.imread(d[0]['seg_file_name'], cv2.IMREAD_GRAYSCALE)\n",
    "    evaluator.add_batch(target/255, mask)\n",
    "\n",
    "MIoU = np.diag(evaluator.confusion_matrix) / (\n",
    "    np.sum(evaluator.confusion_matrix, axis=1) + np.sum(evaluator.confusion_matrix, axis=0) -\n",
    "    np.diag(evaluator.confusion_matrix))\n",
    "Acc = evaluator.Pixel_Accuracy()\n",
    "Acc_class = evaluator.Pixel_Accuracy_Class()\n",
    "mIoU = evaluator.Mean_Intersection_over_Union()\n",
    "FWIoU = evaluator.Frequency_Weighted_Intersection_over_Union()\n",
    "print('Validation:')\n",
    "print('mIoU:{}'.format(MIoU))\n",
    "print(\"Acc:{}, Acc_class:{}, mIoU:{}, fwIoU: {}\".format(Acc, Acc_class, mIoU, FWIoU))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRAW ONLY SEGEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aicenter/Documents/hsu/data/EWSHM/exp3_validation/image/00021.png\n",
      "/home/aicenter/Documents/hsu/data/EWSHM/exp3_validation/image/crop_93.png\n"
     ]
    }
   ],
   "source": [
    "is_trans = 'Trans' in test_dir\n",
    "root, folder_name = '', ''\n",
    "if is_trans:\n",
    "    split_path = file_name.split('/')\n",
    "    folder_name = '_'.join(split_path[-3].split('_')[:-1])\n",
    "    root = '/'.join(split_path[:-3])\n",
    "\n",
    "save_dir = test_dir + '/result/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "mask_color = np.array((0, 255, 0), dtype=\"uint8\")\n",
    "for idx, d in enumerate(test_loader):\n",
    "    file_name = d[0][\"file_name\"]\n",
    "    im = cv2.imread(file_name)\n",
    "    if idx%50==0:\n",
    "        print(file_name)\n",
    "    outputs = predictor(im)\n",
    "    \n",
    "    image_name = file_name.split('/')[-1]\n",
    "    if is_trans:\n",
    "        original_path = '%s/%s/image/%s'%(root, folder_name, image_name)\n",
    "        im = cv2.imread(original_path)\n",
    "    masks = outputs['instances'].pred_masks.cpu().numpy()\n",
    "    masks = masks[outputs['instances'].scores.cpu().numpy() > cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST]\n",
    "    mask = np.sum(masks, axis=0) > 0\n",
    "    roi = im[mask]\n",
    "    im[mask] = ((0.5 * mask_color) + (0.5 * roi)).astype(\"uint8\")\n",
    "    cv2.imwrite(save_dir + file_name.split('/')[-1], im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRAW ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aicenter/Documents/hsu/data/test_dataset/tw_labels/datasets/image/crop_0.png\n",
      "/home/aicenter/Documents/hsu/data/test_dataset/tw_labels/datasets/image/crop_57.png\n"
     ]
    }
   ],
   "source": [
    "is_trans = 'Trans' in test_dir\n",
    "root, folder_name = '', ''\n",
    "if is_trans:\n",
    "    split_path = file_name.split('/')\n",
    "    folder_name = '_'.join(split_path[-3].split('_')[:-1])\n",
    "    root = '/'.join(split_path[:-3])\n",
    "\n",
    "save_dir = test_dir + '/result/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "crack_metadata = MetadataCatalog.get(\"cracks_test\")\n",
    "\n",
    "for idx, d in enumerate(test_loader):\n",
    "    file_name = d[0][\"file_name\"]\n",
    "    im = cv2.imread(file_name)\n",
    "    if idx%50==0:\n",
    "        print(file_name)\n",
    "    outputs = predictor(im)\n",
    "    \n",
    "    image_name = file_name.split('/')[-1]\n",
    "    if is_trans:\n",
    "        original_path = '%s/%s/image/%s'%(root, folder_name, image_name)\n",
    "        im = cv2.imread(original_path)\n",
    "        \n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=crack_metadata, \n",
    "                   scale=1, \n",
    "                   instance_mode=ColorMode.SEGMENTATION   # remove the colors of unsegmented pixels\n",
    "    )\n",
    "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    # save_dir = './result/segmentation/'\n",
    "    cv2.imwrite(save_dir + file_name.split('/')[-1], v.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CECI Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode 1: input with cropped image and do image stitching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at /home/aicenter/Documents/hsu/data/test_dataset/test_ceci/640xh/gt_640_seg.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_w, crop_h = 256, 256\n",
    "ceci_dir = '/home/aicenter/Documents/hsu/data/test_dataset/test_ceci/640xh/%sx%s/image/' %(crop_w, crop_h)\n",
    "source_path = '/home/aicenter/Documents/hsu/data/test_dataset/test_ceci/640xh/gt_640.png'\n",
    "\n",
    "height, width, _ = cv2.imread(source_path).shape\n",
    "x_num, y_num = int(width/crop_w), int(height/crop_h)\n",
    "\n",
    "mask_color = np.array((0, 0, 255), dtype=\"uint8\") \n",
    "whole_image = np.array([])\n",
    "v_im = np.array([])\n",
    "for filename in sorted(os.listdir(ceci_dir)):\n",
    "    count_id = int(filename.split('.')[0])\n",
    "    image_path = ceci_dir+filename\n",
    "    im = cv2.imread(image_path)\n",
    "    outputs = predictor(im)\n",
    "    \n",
    "    masks = outputs['instances'].pred_masks.cpu().numpy()\n",
    "    # masks = masks[outputs['instances'].scores.cpu().numpy() > cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST]\n",
    "    masks = masks[outputs['instances'].scores.cpu().numpy() > 0.5]\n",
    "    mask = np.sum(masks, axis=0) > 0\n",
    "    roi = im[mask]\n",
    "    im[mask] = ((0.5 * mask_color) + (0.5 * roi)).astype(\"uint8\")\n",
    "    if (count_id+1)%y_num == 0:\n",
    "        whole_image = v_im if whole_image.size == 0 else np.hstack((whole_image, v_im))\n",
    "        v_im = np.array([])\n",
    "    else:\n",
    "        v_im = im if v_im.size == 0 else np.vstack((v_im, im))\n",
    "\n",
    "save_path = source_path.split('.png')[0] + '_seg.png'\n",
    "print('Saved at', save_path)\n",
    "cv2.imwrite(save_path, whole_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode 2: input of the whole picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at /home/aicenter/Documents/hsu/data/test_dataset/test_tunnel/3yi_tunnel_seg.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tunnel_image_path = '/home/aicenter/Documents/hsu/data/test_dataset/test_tunnel/3yi_tunnel.png' \n",
    "tunnel_image = cv2.imread(tunnel_image_path)\n",
    "height, width, _ = tunnel_image.shape\n",
    "\n",
    "crop_width, crop_height = (400, 400)\n",
    "mask_color = np.array((0, 255, 0), dtype=\"uint8\") \n",
    "x_num = int(width/crop_width) + 1\n",
    "y_num = int(height/crop_height) + 1\n",
    "max_x = width - crop_width\n",
    "max_y = height - crop_height\n",
    "for x in range(x_num):\n",
    "    for y in range(y_num):\n",
    "        start_x = min(x*crop_width, max_x)\n",
    "        end_x = start_x + crop_width\n",
    "        start_y = min(y*crop_height, max_y)\n",
    "        end_y = start_y + crop_height\n",
    "        test_image = tunnel_image[start_y:end_y, start_x:end_x, :]\n",
    "        outputs = predictor(test_image)\n",
    "\n",
    "        masks = outputs['instances'].pred_masks.cpu().numpy()\n",
    "        # masks = masks[outputs['instances'].scores.cpu().numpy() > cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST]\n",
    "        masks = masks[outputs['instances'].scores.cpu().numpy() > 0.5]\n",
    "        mask = np.sum(masks, axis=0) > 0\n",
    "        roi = test_image[mask]\n",
    "        test_image[mask] = ((0.5 * mask_color) + (0.5 * roi)).astype(\"uint8\")\n",
    "        tunnel_image[start_y:end_y, start_x:end_x, :] = test_image\n",
    "\n",
    "save_path = tunnel_image_path.split('.png')[0] + '_seg.png'\n",
    "print('Saved at', save_path)\n",
    "cv2.imwrite(save_path, tunnel_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('cracks': venv)",
   "language": "python",
   "name": "python36964bitcracksvenvbf75f9d4fb5a488bbbfb5e863882f9c4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
