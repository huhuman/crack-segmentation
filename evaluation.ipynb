{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some common libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime, os\n",
    "import time\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog, transforms, build_detection_test_loader, build_detection_train_loader\n",
    "# from detectron2.engine import DefaultTrainer\n",
    "# from detectron2.structures import BoxMode\n",
    "from dataset.crack_images import get_cracks_dicts_instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting for dataset and model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512 \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (crack)\n",
    "# cfg.MODEL.WEIGHTS = \"/home/aicenter/Documents/hsu/crack-detection/models/Mask R-CNN/HomeInspection/CC140+30+22+35+72_001/model_final.pth\"\n",
    "cfg.MODEL.WEIGHTS = \"/home/aicenter/Documents/hsu/crack_temp/models/IPCSHM/Mask R-CNN/train_cropped_512/model_final.pth\"\n",
    "# cfg.MODEL.WEIGHTS = \"/home/aicenter/Documents/hsu/crack-detection/models/Mask R-CNN/CC140+73+22_Augmented/model_final.pth\"\n",
    "# cfg.MODEL.WEIGHTS = \"/home/aicenter/Documents/hsu/crack-detection/models/Mask R-CNN/ongoing_experiments/chungliao-finetune/model_final.pth\"\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set the testing threshold for this model\n",
    "cfg.DATASETS.TEST = (\"cracks_test\", )\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45516800"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters\n",
    "model_parameters = filter(lambda p: p.requires_grad, predictor.model.backbone.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '/home/aicenter/Documents/hsu/data/CECI_Project/chungliao/cropped_fixed_512/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(name='cracks_test',\n",
       "          thing_classes=['crack'],\n",
       "          thing_colors=[(96, 151, 255)])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DatasetCatalog.clear()\n",
    "DatasetCatalog.register(\"cracks_test\", lambda d= \"test\": get_cracks_dicts_instance(test_dir))\n",
    "MetadataCatalog.get(\"cracks_test\").set(thing_classes=[\"crack\"], thing_colors=[(96, 151, 255)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = build_detection_test_loader(cfg, \"cracks_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_segmentation_single_image(base_image, predictor, input_image=np.array([])):\n",
    "    if not input_image.any():\n",
    "        input_image = base_image\n",
    "    outputs = predictor(input_image)\n",
    "    masks = outputs['instances'].pred_masks.cpu().numpy()\n",
    "    masks = masks[outputs['instances'].scores.cpu().numpy() > cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST]\n",
    "    mask = np.sum(masks, axis=0) > 0\n",
    "    roi = base_image[mask]\n",
    "    base_image[mask] = ((0.4 * mask_color) + (0.6 * roi)).astype(\"uint8\")\n",
    "    return base_image\n",
    "\n",
    "def draw_segmentation_images(base_image, crop_size, predictor, color=np.array((0, 255, 0), dtype=\"uint8\"), input_image=np.array([])):\n",
    "    if not input_image.any():\n",
    "        input_image = base_image\n",
    "    height, width, _ = base_image.shape \n",
    "    crop_width, crop_height = crop_size\n",
    "    x_num = int(width/crop_width) + 1\n",
    "    y_num = int(height/crop_height) + 1\n",
    "    max_x = width - crop_width\n",
    "    max_y = height - crop_height\n",
    "    for x in range(x_num):\n",
    "        for y in range(y_num):\n",
    "            start_x = min(x*crop_width, max_x)\n",
    "            end_x = start_x + crop_width\n",
    "            start_y = min(y*crop_height, max_y)\n",
    "            end_y = start_y + crop_height\n",
    "            _input = input_image[start_y:end_y, start_x:end_x, :]\n",
    "            _base = base_image[start_y:end_y, start_x:end_x, :]\n",
    "            _base = draw_segmentation_single_image(_base, predictor, _input)\n",
    "            base_image[start_y:end_y, start_x:end_x, :] = _base\n",
    "    return base_image\n",
    "\n",
    "def draw_segmentation_and_bbox_single_image(base_image, predictor, meta_dataset, input_image=np.array([])):\n",
    "    vis_metadata = MetadataCatalog.get(meta_dataset)\n",
    "    if not input_image.any():\n",
    "        input_image = base_image\n",
    "    outputs = predictor(input_image)\n",
    "    v = Visualizer(base_image[:, :, ::-1], metadata=vis_metadata, scale=1, instance_mode=ColorMode.SEGMENTATION)\n",
    "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    return v.get_image()[:, :, ::-1]\n",
    "\n",
    "\n",
    "def draw_segmentation_and_bbox_images(base_image, crop_size, predictor, meta_dataset, input_image=np.array([])):\n",
    "    if not input_image.any():\n",
    "        input_image = base_image\n",
    "    height, width, _ = input_image.shape \n",
    "    crop_width, crop_height = crop_size\n",
    "    x_num = int(width/crop_width) + 1\n",
    "    y_num = int(height/crop_height) + 1\n",
    "    max_x = width - crop_width\n",
    "    max_y = height - crop_height\n",
    "    for x in range(x_num):\n",
    "        for y in range(y_num):\n",
    "            start_x = min(x*crop_width, max_x)\n",
    "            end_x = start_x + crop_width\n",
    "            start_y = min(y*crop_height, max_y)\n",
    "            end_y = start_y + crop_height\n",
    "            _input = input_image[start_y:end_y, start_x:end_x, :]\n",
    "            _base = draw_segmentation_and_bbox_single_image(_input, predictor, meta_dataset)\n",
    "            base_image[start_y:end_y, start_x:end_x, :] = _base\n",
    "    return base_image\n",
    "\n",
    "\n",
    "def save_image(path, im):\n",
    "    print('Saved at', path)\n",
    "    cv2.imwrite(path, im)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aicenter/Documents/hsu/data/CECI_Project/chungliao/cropped_fixed_512/image/001_01.png\n",
      "/home/aicenter/Documents/hsu/data/CECI_Project/chungliao/cropped_fixed_512/image/001_71.png\n"
     ]
    }
   ],
   "source": [
    "save_dir = test_dir + '/gt_visualize/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "mask_color = np.array((43, 255, 244), dtype=\"uint8\")\n",
    "for idx, d in enumerate(test_loader):\n",
    "    file_name = d[0][\"file_name\"]\n",
    "    im = cv2.imread(file_name)\n",
    "    if idx%50==0:\n",
    "        print(file_name)\n",
    "    \n",
    "    image_name = file_name.split('/')[-1]\n",
    "    masks = cv2.imread(d[0]['seg_file_name'], cv2.IMREAD_GRAYSCALE)\n",
    "    mask = masks == 255\n",
    "    roi = im[mask]\n",
    "    im[mask] = ((0.5 * mask_color) + (0.5 * roi)).astype(\"uint8\")\n",
    "    cv2.imwrite(save_dir + file_name.split('/')[-1], im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Segmentation: original size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_paths = ['/home/aicenter/Documents/hsu/data/test_dataset/test_tunnel/T3/t3_tunnel.png']\n",
    "root = '/home/aicenter/Documents/hsu/data/project_home_inspection/cracks/exp_combination/test/'\n",
    "root = '/home/aicenter/Documents/hsu/data/project_sinotech/source/HS-N_19K20K_half_01/'\n",
    "root = '/home/aicenter/Documents/hsu/data/publication_IPC-SHM/test/image/'\n",
    "root = '/home/aicenter/Documents/hsu/data/project_home_inspection/cracks/exp_combination/measure_sample/'\n",
    "image_paths = [root + file for file in os.listdir(root)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Mode 1: input of the whole picture and draw segmentation on images***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at /home/aicenter/Documents/hsu/data/project_home_inspection/cracks/exp_combination/measure_sample/../seg/DSC09612_seg.png\n",
      "Saved at /home/aicenter/Documents/hsu/data/project_home_inspection/cracks/exp_combination/measure_sample/../seg/DSC09666_seg.png\n",
      "Saved at /home/aicenter/Documents/hsu/data/project_home_inspection/cracks/exp_combination/measure_sample/../seg/DSC09652_seg.png\n",
      "Saved at /home/aicenter/Documents/hsu/data/project_home_inspection/cracks/exp_combination/measure_sample/../seg/DSC09620_seg.png\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(root + '../seg/', exist_ok=True)\n",
    "for image_path in image_paths:\n",
    "    base_image = cv2.imread(image_path)\n",
    "    input_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    input_image = cv2.cvtColor(input_image, cv2.COLOR_GRAY2BGR)\n",
    "    height, width, _ = input_image.shape \n",
    "    crop_size = (512, 512)\n",
    "    base_image = draw_segmentation_single_image(base_image, crop_size, predictor, input_image=input_image)\n",
    "    save_image(root + '../seg/' + image_path.split('/')[-1][:-4] + '_seg.png', base_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Mode 2: input of the whole picture and draw only segmentation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at /home/aicenter/Documents/hsu/data/project_home_inspection/cracks/exp_combination/measure_sample/../seg_only/DSC09612.png\n",
      "Saved at /home/aicenter/Documents/hsu/data/project_home_inspection/cracks/exp_combination/measure_sample/../seg_only/DSC09666.png\n",
      "Saved at /home/aicenter/Documents/hsu/data/project_home_inspection/cracks/exp_combination/measure_sample/../seg_only/DSC09652.png\n",
      "Saved at /home/aicenter/Documents/hsu/data/project_home_inspection/cracks/exp_combination/measure_sample/../seg_only/DSC09620.png\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(root + '../seg_only/', exist_ok=True)\n",
    "for image_path in image_paths:\n",
    "    filename = image_path.split('/')[-1]\n",
    "    input_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    input_image = cv2.cvtColor(input_image, cv2.COLOR_GRAY2BGR)\n",
    "    height, width, _ = input_image.shape\n",
    "    base_image = np.zeros((height, width, 3))  \n",
    "    crop_size = (512, 512)\n",
    "    \n",
    "    base_image = draw_segmentation_images(base_image, crop_size, predictor, input_image=input_image)\n",
    "    \n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    dilation = cv2.dilate(base_image, kernel, iterations = 5)\n",
    "    mask = np.sum(dilation, axis=2) > 0\n",
    "    base_image = np.ones((height, width, 3))*255    \n",
    "    roi = base_image[mask]\n",
    "    base_image[mask] = ((1 * np.array((0, 255, 0), dtype=\"uint8\") + (0 * roi))).astype(\"uint8\")\n",
    "    save_image(root + '../seg_only/' + filename[:-4] + '.png', base_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Mode 3: input of the whole picture and seg only predicted parts overlap to gt***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(root + '../overlap/', exist_ok=True)\n",
    "for image_path in image_paths:\n",
    "    filename = image_path.split('/')[-1]\n",
    "    input_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    input_image = cv2.cvtColor(input_image, cv2.COLOR_GRAY2BGR)\n",
    "    height, width, _ = input_image.shape \n",
    "    base_image = np.zeros((height, width, 3))  \n",
    "    \n",
    "    crop_size = (512, 512)\n",
    "    base_image = draw_segmentation_images(base_image, crop_size, predictor, input_image=input_image)\n",
    "    \n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    dilation = cv2.dilate(base_image, kernel, iterations = 5)\n",
    "    mask = np.sum(dilation, axis=2) > 0\n",
    "    base_image = cv2.imread(root + '../gt/' + filename[:-4] + '.png')\n",
    "    base_image = cv2.resize(base_image, (width, height), interpolation=cv2.INTER_CUBIC)\n",
    "    roi = base_image[mask]\n",
    "    base_image[mask] = ((1 * np.array((0, 255, 0), dtype=\"uint8\") + (0 * roi))).astype(\"uint8\")\n",
    "    \n",
    "    save_image(root + '../overlap/' + filename[:-4] + '_overlap.png', base_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Segmentation: cropped size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Mode 1: do image stitching***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mode 1: input with cropped image and do image stitching\n",
    "crop_w, crop_h = 256, 256\n",
    "ceci_dir = '/home/aicenter/Documents/hsu/data/test_dataset/test_ceci/640xh/%sx%s/image/' %(crop_w, crop_h)\n",
    "source_path = '/home/aicenter/Documents/hsu/data/test_dataset/test_ceci/640xh/gt_640.png'\n",
    "\n",
    "height, width, _ = cv2.imread(source_path).shape\n",
    "x_num, y_num = int(width/crop_w), int(height/crop_h)\n",
    "\n",
    "mask_color = np.array((0, 0, 255), dtype=\"uint8\") \n",
    "whole_image = np.array([])\n",
    "v_im = np.array([])\n",
    "for filename in sorted(os.listdir(ceci_dir)):\n",
    "    count_id = int(filename.split('.')[0])\n",
    "    image_path = ceci_dir+filename\n",
    "    im = cv2.imread(image_path)\n",
    "    im = run_prediction_and_draw_single_image(im, predictor)\n",
    "    \n",
    "    if (count_id+1)%y_num == 0:\n",
    "        whole_image = v_im if whole_image.size == 0 else np.hstack((whole_image, v_im))\n",
    "        v_im = np.array([])\n",
    "    else:\n",
    "        v_im = im if v_im.size == 0 else np.vstack((v_im, im))\n",
    "\n",
    "save_image(source_path.split('.png')[0] + '_seg.png', whole_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Box+Segmentation: original size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_paths = ['/home/aicenter/Documents/hsu/data/test_dataset/test_tunnel/3yi_tunnel.png']\n",
    "# root = '/home/aicenter/Documents/hsu/data/test_dataset/test_tunnel/CL/img/'\n",
    "# root = '/home/aicenter/Documents/hsu/data/test_dataset/test_tunnel/south/crop/'\n",
    "root = '/home/aicenter/Documents/hsu/data/project_home_inspection/cracks/exp_combination/test/'\n",
    "root = '/home/aicenter/Documents/hsu/data/project_home_inspection/cracks/exp_combination/measure_sample/'\n",
    "image_paths = [root + file for file in os.listdir(root)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at /home/aicenter/Documents/hsu/data/project_home_inspection/cracks/exp_combination/measure_sample/../bbox/DSC09612_bbox.png\n",
      "Saved at /home/aicenter/Documents/hsu/data/project_home_inspection/cracks/exp_combination/measure_sample/../bbox/DSC09666_bbox.png\n",
      "Saved at /home/aicenter/Documents/hsu/data/project_home_inspection/cracks/exp_combination/measure_sample/../bbox/DSC09652_bbox.png\n",
      "Saved at /home/aicenter/Documents/hsu/data/project_home_inspection/cracks/exp_combination/measure_sample/../bbox/DSC09620_bbox.png\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(root + '../bbox/', exist_ok=True)\n",
    "for image_path in image_paths:\n",
    "    filename = image_path.split('/')[-1]\n",
    "    base_image = cv2.imread(image_path)\n",
    "    input_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    input_image = cv2.cvtColor(input_image, cv2.COLOR_GRAY2BGR)\n",
    "    crop_size = (512, 512)\n",
    "    base_image = draw_segmentation_and_bbox_images(base_image, crop_size, predictor, \"cracks_test\", input_image=input_image )\n",
    "         \n",
    "    save_image(root + '../bbox/' + filename[:-4] + '_bbox.png', base_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Box+Segmentation: cropped size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aicenter/Documents/hsu/data/IPC-SHM-P1/experiments/val_120+80/image/001.png\n"
     ]
    }
   ],
   "source": [
    "save_dir = test_dir + '/result/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for idx, d in enumerate(test_loader):\n",
    "    file_name = d[0][\"file_name\"]\n",
    "    base_image = cv2.imread(file_name)\n",
    "    base_image = draw_segmentation_and_bbox_single_image(base_image, predictor, \"cracks_test\")\n",
    "    if idx%50==0:\n",
    "        print(file_name)\n",
    "    image_name = file_name.split('/')[-1]\n",
    "    cv2.imwrite(save_dir + file_name.split('/')[-1], base_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## mIoU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# borrows from pytorch-deeplab-xception\n",
    "from utils.metrics import Evaluator\n",
    "evaluator = Evaluator(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aicenter/Documents/hsu/data/CECI_Project/chungliao/cropped_fixed_512/image/001_01.png\n",
      "/home/aicenter/Documents/hsu/data/CECI_Project/chungliao/cropped_fixed_512/image/001_71.png\n",
      "Validation:\n",
      "mIoU:[0.9912531  0.08246476]\n",
      "Acc:0.9912599690755208, Acc_class:0.5720960407605691, mIoU:0.5368589284189166, fwIoU: 0.9864442041603741\n"
     ]
    }
   ],
   "source": [
    "is_trans = 'Trans' in test_dir\n",
    "root, folder_name = '', ''\n",
    "if is_trans:\n",
    "    split_path = file_name.split('/')\n",
    "    folder_name = '_'.join(split_path[-3].split('_')[:-1])\n",
    "    root = '/'.join(split_path[:-3])\n",
    "    \n",
    "evaluator.reset()\n",
    "for idx, d in enumerate(test_loader):\n",
    "    file_name = d[0][\"file_name\"]\n",
    "    im = cv2.imread(file_name)\n",
    "    if idx%50==0:\n",
    "        print(file_name)\n",
    "    outputs = predictor(im)\n",
    "    \n",
    "    image_name = file_name.split('/')[-1]\n",
    "    if is_trans:\n",
    "        original_path = '%s/%s/image/%s'%(root, folder_name, image_name)\n",
    "        im = cv2.imread(original_path)\n",
    "    masks = outputs['instances'].pred_masks.cpu().numpy()\n",
    "    masks = masks[outputs['instances'].scores.cpu().numpy() > cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST]\n",
    "    mask = np.sum(masks, axis=0) > 0\n",
    "    target = cv2.imread(d[0]['seg_file_name'], cv2.IMREAD_GRAYSCALE)\n",
    "    evaluator.add_batch(target/255, mask)\n",
    "\n",
    "MIoU = np.diag(evaluator.confusion_matrix) / (\n",
    "    np.sum(evaluator.confusion_matrix, axis=1) + np.sum(evaluator.confusion_matrix, axis=0) -\n",
    "    np.diag(evaluator.confusion_matrix))\n",
    "Acc = evaluator.Pixel_Accuracy()\n",
    "Acc_class = evaluator.Pixel_Accuracy_Class()\n",
    "mIoU = evaluator.Mean_Intersection_over_Union()\n",
    "FWIoU = evaluator.Frequency_Weighted_Intersection_over_Union()\n",
    "print('Validation:')\n",
    "print('mIoU:{}'.format(MIoU))\n",
    "print(\"Acc:{}, Acc_class:{}, mIoU:{}, fwIoU: {}\".format(Acc, Acc_class, mIoU, FWIoU))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## mAP計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '/home/aicenter/Documents/hsu/data/CECI_Project/chungliao/val_cropped_fixed_512/'\n",
    "DatasetCatalog.clear()\n",
    "DatasetCatalog.register(\"cracks_test\", lambda d= \"test\": get_cracks_dicts_instance(test_dir))\n",
    "MetadataCatalog.get(\"cracks_test\").set(thing_classes=[\"crack\"], thing_colors=[(96, 151, 255)])\n",
    "test_loader = build_detection_test_loader(cfg, \"cracks_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.evaluation import COCOEvaluator\n",
    "evaluator = COCOEvaluator(\"cracks_test\", cfg, True, 'coco_eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aicenter/Documents/hsu/data/CECI_Project/chungliao/val_cropped_fixed_512/image/001_40.png\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.00 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.00 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.169\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.314\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.166\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.208\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.125\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.156\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.244\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.244\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.230\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "COCOeval_opt.evaluate() finished in 0.00 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.00 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bbox',\n",
       "              {'AP': 16.91559389455429,\n",
       "               'AP50': 31.374405297672624,\n",
       "               'AP75': 16.58040804080408,\n",
       "               'APs': 20.759427642573737,\n",
       "               'APm': 12.517680339462517,\n",
       "               'APl': nan}),\n",
       "             ('segm',\n",
       "              {'AP': 0.0,\n",
       "               'AP50': 0.0,\n",
       "               'AP75': 0.0,\n",
       "               'APs': 0.0,\n",
       "               'APm': 0.0,\n",
       "               'APl': nan})])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.reset()\n",
    "\n",
    "for idx, d in enumerate(test_loader):\n",
    "    file_name = d[0][\"file_name\"]\n",
    "    im = cv2.imread(file_name)\n",
    "    if idx%50==0:\n",
    "        print(file_name)\n",
    "    outputs = predictor(im)\n",
    "    evaluator.process(d, [outputs])\n",
    "    \n",
    "evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geometric Properties Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist(x1, y1, x2, y2):\n",
    "    return ((x2-x1)**2 + (y1-y2)**2)**0.5\n",
    "\n",
    "def is_merged(box_1, box_2, threshold=100):\n",
    "    left_1, top_1, right_1, bottom_1 = box_1\n",
    "    left_2, top_2, right_2, bottom_2 = box_2\n",
    "    if left_1 > left_2 and right_1 < right_2:\n",
    "        if top_1 > top_2 and bottom_1 < bottom_2:\n",
    "            return True\n",
    "    coner_1 = [(right_1, bottom_1), (right_1, top_1), (left_1, bottom_1), (left_1, top_1)]\n",
    "    coner_2 = [(right_2, bottom_2), (right_2, top_2), (left_2, bottom_2), (left_2, top_2)]\n",
    "    # cal minimum distance between coner points\n",
    "    val = 10**8\n",
    "    for c1 in coner_1:\n",
    "        for c2 in coner_2:\n",
    "            val = min(val, get_dist(c1[0], c1[1], c2[0], c2[1]))                      \n",
    "    return val < threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines(image, points):\n",
    "    for i in range(len(points)):\n",
    "        min_index, min_val = -1, 10**8\n",
    "        for j in range(i+1, len(points)):\n",
    "            x1, y1 = points[i]\n",
    "            x2, y2 = points[j]\n",
    "            dist = get_dist(x1, y1, x2, y2)\n",
    "            if dist <= 1.1:\n",
    "                min_index = j\n",
    "                break\n",
    "            if min_val > dist:\n",
    "                min_val = dist\n",
    "                min_index = j\n",
    "        if min_index != -1:\n",
    "            cv2.line(image, points[i], points[min_index], (255,255,255), 1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at /home/aicenter/Documents/hsu/data/project_home_inspection/cracks/exp_combination/measure_sample/../bbox/DSC09612.png\n",
      "Saved at /home/aicenter/Documents/hsu/data/project_home_inspection/cracks/exp_combination/measure_sample/../bbox/DSC09666.png\n",
      "Saved at /home/aicenter/Documents/hsu/data/project_home_inspection/cracks/exp_combination/measure_sample/../bbox/DSC09652.png\n",
      "Saved at /home/aicenter/Documents/hsu/data/project_home_inspection/cracks/exp_combination/measure_sample/../bbox/DSC09620.png\n"
     ]
    }
   ],
   "source": [
    "crack_metadata = MetadataCatalog.get(\"cracks_test\")\n",
    "\n",
    "root = '/home/aicenter/Documents/hsu/data/project_home_inspection/cracks/exp_combination/measure_sample/'\n",
    "# root = '/home/aicenter/Documents/hsu/data/project_home_inspection/cracks/exp_combination/test/'\n",
    "crack_image_paths = [root + file for file in os.listdir(root)]\n",
    "\n",
    "os.makedirs(root + '../bbox/', exist_ok=True)\n",
    "\n",
    "for image_path in crack_image_paths:\n",
    "    filename = image_path.split('/')[-1]\n",
    "    crack_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    crack_image = cv2.cvtColor(crack_image, cv2.COLOR_GRAY2BGR)\n",
    "    height, width, _ = crack_image.shape \n",
    "    crop_width, crop_height = (512, 512)\n",
    "    mask_color = np.array((0, 255, 0), dtype=\"uint8\") \n",
    "    x_num = int(width/crop_width) + 1\n",
    "    y_num = int(height/crop_height) + 1\n",
    "    max_x = width - crop_width\n",
    "    max_y = height - crop_height\n",
    "    \n",
    "    box_list = []\n",
    "    mask_list = []\n",
    "    ref_pts = []\n",
    "    for x in range(x_num):\n",
    "        for y in range(y_num):\n",
    "            start_x = min(x*crop_width, max_x)\n",
    "            end_x = start_x + crop_width\n",
    "            start_y = min(y*crop_height, max_y)\n",
    "            end_y = start_y + crop_height\n",
    "            test_image = crack_image[start_y:end_y, start_x:end_x, :]\n",
    "            \n",
    "            outputs = predictor(test_image)\n",
    "            bboxes = outputs['instances'].pred_boxes.tensor.cpu().numpy()\n",
    "            bboxes = bboxes[outputs['instances'].scores.cpu().numpy() > 0.5]\n",
    "            if len(bboxes) == 0:\n",
    "                continue\n",
    "                \n",
    "            masks = outputs['instances'].pred_masks.cpu().numpy()\n",
    "            masks = masks[outputs['instances'].scores.cpu().numpy() > 0.5]\n",
    "            \n",
    "            for bbox, mask in zip(bboxes, masks):\n",
    "                left, top, right, bottom = list(map(int, bbox))\n",
    "                left += start_x\n",
    "                top += start_y\n",
    "                right += start_x\n",
    "                bottom += start_y\n",
    "#                 if (right-left)*(bottom-top)/width/height < 4e-4:\n",
    "#                     continue\n",
    "                box_list.append([left, top, right, bottom])\n",
    "                mask_list.append(mask)\n",
    "                ref_pts.append((start_x, end_x, start_y, end_y))\n",
    "                \n",
    "    if box_list != []:\n",
    "        box_list, mask_list, ref_pts = zip(*sorted(zip(box_list, mask_list, ref_pts), key=lambda x: x[0]))\n",
    "        mask_groups = [[0]]\n",
    "        box_groups = [[box_list[0]]]\n",
    "        for i in range(1, len(box_list)):\n",
    "            candidate = box_list[i]\n",
    "            ismatch = False\n",
    "            for gindex in range(len(box_groups)):\n",
    "                if ismatch:\n",
    "                    break\n",
    "                for box in box_groups[gindex]:\n",
    "                    if is_merged(candidate, box, 30):\n",
    "                        box_groups[gindex].append(candidate)\n",
    "                        mask_groups[gindex].append(i)\n",
    "                        ismatch = True\n",
    "                        break\n",
    "            if not ismatch:\n",
    "                box_groups.append([candidate])\n",
    "                mask_groups.append([i])\n",
    "\n",
    "        colors = [plt.cm.plasma(i/float(len(box_groups))) for i in range(len(box_groups))]\n",
    "        for num, (boxes, mask_indexes) in enumerate(zip(box_groups, mask_groups)):\n",
    "            color = list(map(lambda x:int(x*255), colors[num][:3]))\n",
    "            \n",
    "            output_left, output_top, output_right, output_bottom = 10**8, 10**8, -1, -1\n",
    "            boxes = sorted(boxes, key=lambda x: x[0])\n",
    "            im = np.zeros((height, width))*255\n",
    "            \n",
    "            for box, index in zip(boxes, mask_indexes):\n",
    "                left, top, right, bottom = box\n",
    "                output_left = min(output_left, left)\n",
    "                output_top = min(output_top, top)\n",
    "                output_right = max(output_right, right)\n",
    "                output_bottom = max(output_bottom, bottom)\n",
    "                \n",
    "                \n",
    "                mask = mask_list[index]\n",
    "                start_x, end_x, start_y, end_y = ref_pts[index]\n",
    "                im[start_y:end_y, start_x:end_x] += mask\n",
    "                \n",
    "            cv2.rectangle(crack_image, (output_left, output_top), (output_right, output_bottom), color, 5)\n",
    "            \n",
    "            mask = im > 0\n",
    "            points = list(np.argwhere(mask))\n",
    "            if len(points) >= 2:\n",
    "                points = sorted(points, key=lambda x: x[1])\n",
    "                slope = (points[0][0]-points[-1][0])*(points[0][1]-points[-1][1])\n",
    "                if slope < 0: #座標軸為向下向右正\n",
    "                    cv2.line(crack_image, (output_left, output_bottom), (output_right, output_top), color, 1)\n",
    "                else:\n",
    "                    cv2.line(crack_image, (output_left, output_top), (output_right, output_bottom), color, 1)\n",
    "            color = np.array(color, dtype=\"uint8\") \n",
    "            roi = crack_image[mask]\n",
    "            crack_image[mask] = ((0.4 * color) + (0.6 * roi)).astype(\"uint8\")\n",
    "            \n",
    "    \n",
    "    \n",
    "    save_path = root + '../bbox/' + filename[:-4] + '.png'\n",
    "    print('Saved at', save_path)\n",
    "    cv2.imwrite(save_path, crack_image)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IPC-SHM Draw Cropped Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# borrows from pytorch-deeplab-xception\n",
    "from utils.metrics import Evaluator\n",
    "evaluator = Evaluator(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_trans = 'Trans' in test_dir\n",
    "root, folder_name = '', ''\n",
    "if is_trans:\n",
    "    split_path = file_name.split('/')\n",
    "    folder_name = '_'.join(split_path[-3].split('_')[:-1])\n",
    "    root = '/'.join(split_path[:-3])\n",
    "    \n",
    "evaluator.reset()\n",
    "for idx, d in enumerate(test_loader):\n",
    "    file_name = d[0][\"file_name\"]\n",
    "    im = cv2.imread(file_name)\n",
    "    if idx%50==0:\n",
    "        print(file_name)\n",
    "    outputs = predictor(im)\n",
    "    \n",
    "    image_name = file_name.split('/')[-1]\n",
    "    if is_trans:\n",
    "        original_path = '%s/%s/image/%s'%(root, folder_name, image_name)\n",
    "        im = cv2.imread(original_path)\n",
    "    masks = outputs['instances'].pred_masks.cpu().numpy()\n",
    "    masks = masks[outputs['instances'].scores.cpu().numpy() > cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST]\n",
    "    mask = np.sum(masks, axis=0) > 0\n",
    "    target = cv2.imread(d[0]['seg_file_name'], cv2.IMREAD_GRAYSCALE)\n",
    "    evaluator.add_batch(target/255, mask)\n",
    "\n",
    "MIoU = np.diag(evaluator.confusion_matrix) / (\n",
    "    np.sum(evaluator.confusion_matrix, axis=1) + np.sum(evaluator.confusion_matrix, axis=0) -\n",
    "    np.diag(evaluator.confusion_matrix))\n",
    "Acc = evaluator.Pixel_Accuracy()\n",
    "Acc_class = evaluator.Pixel_Accuracy_Class()\n",
    "mIoU = evaluator.Mean_Intersection_over_Union()\n",
    "FWIoU = evaluator.Frequency_Weighted_Intersection_over_Union()\n",
    "print('Validation:')\n",
    "print('mIoU:{}'.format(MIoU))\n",
    "print(\"Acc:{}, Acc_class:{}, mIoU:{}, fwIoU: {}\".format(Acc, Acc_class, mIoU, FWIoU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aicenter/Documents/hsu/data/IPC-SHM-P1/experiments/val_120+80/image/001.png\n"
     ]
    }
   ],
   "source": [
    "save_dir = test_dir + '/result/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "mask_color = np.array((0, 255, 0), dtype=\"uint8\")\n",
    "for idx, d in enumerate(test_loader):\n",
    "    file_name = d[0][\"file_name\"]\n",
    "    im = cv2.imread(file_name)\n",
    "    if idx%50==0:\n",
    "        print(file_name)\n",
    "    height, width, _ = im.shape\n",
    "    h_split_number = int(height/size)\n",
    "    w_split_number = int(width/size)\n",
    "    whole_image = np.array([])\n",
    "    v_im = np.array([])\n",
    "    for w_num in range(w_split_number):\n",
    "        start_x = w_num*size\n",
    "        end_x = start_x + size\n",
    "        for h_num in range(h_split_number):\n",
    "            start_y = h_num*size\n",
    "            end_y = start_y + size\n",
    "            cropped_image = im[start_y:end_y, start_x:end_x, :]\n",
    "            outputs = predictor(cropped_image)\n",
    "            masks = outputs['instances'].pred_masks.cpu().numpy()\n",
    "            masks = masks[outputs['instances'].scores.cpu().numpy() > cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST]\n",
    "            mask = np.sum(masks, axis=0) > 0\n",
    "            roi = cropped_image[mask]\n",
    "            cropped_image[mask] = ((0.5 * mask_color) + (0.5 * roi)).astype(\"uint8\")\n",
    "            v_im = cropped_image if v_im.size == 0 else np.vstack((v_im, cropped_image))\n",
    "        \n",
    "        whole_image = v_im if whole_image.size == 0 else np.hstack((whole_image, v_im))\n",
    "        v_im = np.array([])\n",
    "    cv2.imwrite(save_dir + file_name.split('/')[-1], whole_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = cv2.imread('/home/aicenter/Documents/hsu/data/test_dataset/test_tunnel/south/img/SN_437475000_437500000.tif')\n",
    "crop_im = im[350:-1750, 40:-110, :]\n",
    "cv2.imwrite('/home/aicenter/Documents/hsu/data/test_dataset/test_tunnel/south/img/SN_437475000_437500000_crop.png', crop_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('cracks': venv)",
   "language": "python",
   "name": "python36964bitcracksvenvbf75f9d4fb5a488bbbfb5e863882f9c4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
